{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"uAzgcdmYdNny"},"outputs":[],"source":["# install mediapipe\n","!pip install mediapipe"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BzU40SjDq6vK"},"outputs":[],"source":["# read cloud directory\n","from google.colab import drive\n","drive.mount('/content/gdrive') "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XBVXQcxSrCTx"},"outputs":[],"source":["import cv2\n","import mediapipe as mp\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","def media_pipe(resource, counter):\n","  # initialize mediapipe pose solution\n","  mp_pose = mp.solutions.pose\n","  mp_draw = mp.solutions.drawing_utils\n","  pose = mp_pose.Pose()\n","\n","  img = resource #讀檔案\n","\n","  while True:\n","      # resize image/frame so we can accommodate it on our screen\n","      #img = cv2.resize(img, (600, 400))\n","\n","      # do Pose detection\n","      results = pose.process(img)\n","      # draw the detected pose on original picture\n","      mp_draw.draw_landmarks(img, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n","                            mp_draw.DrawingSpec((255, 0, 0), 40, 40),\n","                            mp_draw.DrawingSpec((255, 0, 255), 40, 40)\n","                            )\n","      plt.imshow(img)\n","      plt.show()\n","\n","      # Extract and draw pose on plain white image\n","      h, w, c = img.shape   # get shape of original frame\n","      opImg = np.zeros([h, w, c])  # create blank image with original frame size\n","      opImg.fill(0)  # set white background. put 0 if you want to make it black\n","\n","      # draw extracted pose on black white image\n","      mp_draw.draw_landmarks(opImg, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n","                            mp_draw.DrawingSpec((255, 0, 0), 25, 25),#關節點顏色\n","                            mp_draw.DrawingSpec((0, 255, 0), 40, 40)#骨骼顏色 \n","                            )\n","      # display extracted pose on blank images\n","      plt.imshow(opImg.astype('uint8'))\n","      plt.axis('off') # 移除橫軸和縱軸\n","      # save detected pose image\n","      plt.savefig(\"/content/gdrive/MyDrive/Colab_Notebooks/Sitting_posture/dataset_pose/pose_wrong/xpose_{}.jpg\".format(counter), bbox_inches='tight', pad_inches=0)\n","      plt.show()\n","\n","      break"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8MuQC9kArTzA"},"outputs":[],"source":["# test - read image\n","src1 = cv2.imread('/content/gdrive/MyDrive/Colab_Notebooks/Sitting_posture/dataset_raw/tang_correct_1.png')\n","media_pipe(src1, 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"psleArDWrtIa"},"outputs":[],"source":["# transform raw images into pure pose image\n","import os\n","import cv2\n","\n","# one person's file at once\n","%cd '/content/gdrive/MyDrive/Colab_Notebooks/Sitting_posture/dataset_raw/raw_wrong/cash' \n","\n","\n","img_counter = 193 # keep updated\n","\n","for filename in os.listdir():\n","    if filename.endswith(\"png\"): \n","        print(filename)\n","        img = cv2.imread(filename)\n","        media_pipe(img, img_counter)\n","        img_counter += 1"]},{"cell_type":"code","source":["# jpg to png\n","from PIL import Image\n","import os\n","\n","%cd '/content/gdrive/MyDrive/Colab_Notebooks/Sitting_posture/dataset_pose/pose_wrong'\n","\n","for filename in os.listdir():\n","      im1 = Image.open('/content/gdrive/MyDrive/Colab_Notebooks/Sitting_posture/dataset_pose/pose_wrong/{}'.format(filename))\n","      filename = filename.replace(\".jpg\", \".png\")\n","      im1.save(r'/content/gdrive/MyDrive/Colab_Notebooks/Sitting_posture/dataset_pose/wrong/{}'.format(filename)) "],"metadata":{"id":"bgllH4XL4gL4"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"private_outputs":true,"authorship_tag":"ABX9TyNahHZoLKNSt9YwN9q6zptH"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}